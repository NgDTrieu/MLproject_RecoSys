{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This module runs a 5-Fold CV for all the algorithms (default parameters) on\n",
    "the movielens datasets, and reports average RMSE, MAE, and total computation\n",
    "time.  It is used for making tables in the README.md file'''\n",
    "\n",
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import six\n",
    "from tabulate import tabulate\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import NormalPredictor\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The algorithms to cross-validate\n",
    "classes = (SVD, NMF, SlopeOne, KNNBasic, KNNWithMeans, KNNBaseline,\n",
    "           CoClustering, BaselineOnly, NormalPredictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ugly dict to map algo names and datasets to their markdown links in the table\n",
    "stable = 'http://surprise.readthedocs.io/en/stable/'\n",
    "LINK = {'SVD': '[{}]({})'.format('SVD',\n",
    "                                 stable +\n",
    "                                 'matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD'),\n",
    "        'SVDpp': '[{}]({})'.format('SVD++',\n",
    "                                   stable +\n",
    "                                   'matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVDpp'),\n",
    "        'NMF': '[{}]({})'.format('NMF',\n",
    "                                 stable +\n",
    "                                 'matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF'),\n",
    "        'SlopeOne': '[{}]({})'.format('Slope One',\n",
    "                                      stable +\n",
    "                                      'slope_one.html#surprise.prediction_algorithms.slope_one.SlopeOne'),\n",
    "        'KNNBasic': '[{}]({})'.format('k-NN',\n",
    "                                      stable +\n",
    "                                      'knn_inspired.html#surprise.prediction_algorithms.knns.KNNBasic'),\n",
    "        'KNNWithMeans': '[{}]({})'.format('Centered k-NN',\n",
    "                                          stable +\n",
    "                                          'knn_inspired.html#surprise.prediction_algorithms.knns.KNNWithMeans'),\n",
    "        'KNNBaseline': '[{}]({})'.format('k-NN Baseline',\n",
    "                                         stable +\n",
    "                                         'knn_inspired.html#surprise.prediction_algorithms.knns.KNNBaseline'),\n",
    "        'CoClustering': '[{}]({})'.format('Co-Clustering',\n",
    "                                          stable +\n",
    "                                          'co_clustering.html#surprise.prediction_algorithms.co_clustering.CoClustering'),\n",
    "        'BaselineOnly': '[{}]({})'.format('Baseline',\n",
    "                                          stable +\n",
    "                                          'basic_algorithms.html#surprise.prediction_algorithms.baseline_only.BaselineOnly'),\n",
    "        'NormalPredictor': '[{}]({})'.format('Random',\n",
    "                                             stable +\n",
    "                                             'basic_algorithms.html#surprise.prediction_algorithms.random_pred.NormalPredictor')\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Real Ratings\n",
    "ratings = pd.read_pickle('../.tmp/ratings_pickle')\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['userID', 'itemID', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Creation of the dataframe. Column names are irrelevant.\n",
    "# ratings_dict = {'itemID': [1, 1, 1, 2, 2],\n",
    "#                 'userID': [9, 32, 2, 45, 'user_foo'],\n",
    "#                 'rating': [3, 2, 4, 3, 1]}\n",
    "# df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "# # A reader is still needed but only the rating_scale param is requiered.\n",
    "# reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# # The columns must correspond to user id, item id and ratings (in that order).\n",
    "# data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data size: 6584636\n",
      "Data size after conversion: 6584636\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original data size: {len(ratings)}\")\n",
    "print(f\"Data size after conversion: {len(data.raw_ratings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|:----------------------------------------------------------------------------------------------------------------------------------|------:|-----:|:--------|\n",
      "| [SVD](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD) | 0.846 | 0.65 | 0:16:33 |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m classes:\n\u001b[32m     14\u001b[39m     start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     out = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrmse\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmae\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     cv_time = \u001b[38;5;28mstr\u001b[39m(datetime.timedelta(seconds=\u001b[38;5;28mint\u001b[39m(time.time() - start)))\n\u001b[32m     17\u001b[39m     link = LINK[klass.\u001b[34m__name__\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\model_selection\\validation.py:108\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(algo, data, measures, cv, return_train_measures, n_jobs, pre_dispatch, verbose)\u001b[39m\n\u001b[32m    102\u001b[39m cv = get_cv(cv)\n\u001b[32m    104\u001b[39m delayed_list = (\n\u001b[32m    105\u001b[39m     delayed(fit_and_score)(algo, trainset, testset, measures, return_train_measures)\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (trainset, testset) \u001b[38;5;129;01min\u001b[39;00m cv.split(data)\n\u001b[32m    107\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m out = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m (test_measures_dicts, train_measures_dicts, fit_times, test_times) = \u001b[38;5;28mzip\u001b[39m(*out)\n\u001b[32m    112\u001b[39m test_measures = \u001b[38;5;28mdict\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\model_selection\\validation.py:173\u001b[39m, in \u001b[36mfit_and_score\u001b[39m\u001b[34m(algo, trainset, testset, measures, return_train_measures)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Helper method that trains an algorithm and compute accuracy measures on\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03ma testset. Also report train and test times.\u001b[39;00m\n\u001b[32m    144\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    169\u001b[39m \u001b[33;03m        - The testing time in seconds.\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    172\u001b[39m start_fit = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m \u001b[43malgo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m fit_time = time.time() - start_fit\n\u001b[32m    175\u001b[39m start_test = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx:658\u001b[39m, in \u001b[36msurprise.prediction_algorithms.matrix_factorization.NMF.fit\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx:708\u001b[39m, in \u001b[36msurprise.prediction_algorithms.matrix_factorization.NMF.sgd\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\trainset.py:194\u001b[39m, in \u001b[36mTrainset.all_ratings\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m u, u_ratings \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ur.items():\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m u_ratings:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m u, i, r\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# The algorithms to cross-validate\n",
    "classes = (SVD, NMF, SlopeOne, KNNBasic, KNNWithMeans, KNNBaseline,\n",
    "           CoClustering, BaselineOnly, NormalPredictor)\n",
    "\n",
    "# set RNG\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# set KFold\n",
    "kf = KFold(random_state=0)  # folds will be the same for all algorithms.\n",
    "\n",
    "table = []\n",
    "for klass in classes:\n",
    "    start = time.time()\n",
    "    out = cross_validate(klass(), data, ['rmse', 'mae'], kf)\n",
    "    cv_time = str(datetime.timedelta(seconds=int(time.time() - start)))\n",
    "    link = LINK[klass.__name__]\n",
    "    mean_rmse = '{:.3f}'.format(np.mean(out['test_rmse']))\n",
    "    mean_mae = '{:.3f}'.format(np.mean(out['test_mae']))\n",
    "\n",
    "    new_line = [link, mean_rmse, mean_mae, cv_time]\n",
    "    print(tabulate([new_line], tablefmt=\"pipe\"))  # print current algo perf\n",
    "    table.append(new_line)\n",
    "\n",
    "header = ['RMSE',\n",
    "          'MAE',\n",
    "          'Time'\n",
    "          ]\n",
    "print(tabulate(table, header, tablefmt=\"pipe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
